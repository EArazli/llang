System outline (all layers)

Goal: a modular “language workbench” where any doctrine (categorical / compositional structure) can be defined as a library artifact, equipped (optionally) with rewrite orientation + coherence data, and then used by arbitrary surface syntaxes and backends. No doctrine is special-cased in the core. The core provides generic machinery; doctrines get nicer automation only when their authors provide more structure.

Layers

Layer M (Meta / Kernel: presented rewriting 2-theories)

What it is: a generic engine for:
	•	presenting theories as generators + equations, optionally oriented as rewrite rules
	•	rewriting, normalization (when possible)
	•	critical pair (branching) enumeration
	•	coherence obligations (join requirements), and a place to store/validate joiners
	•	separation of rules into “structural vs computational” for relative coherence

What it does NOT assume: CCC, STLC, lambda calculus, any particular doctrine.

Layer D (Doctrine libraries)

A doctrine is just data built using Layer M:
	•	signature-ish data (optional early on)
	•	a set of equations/rules with metadata (orientation, structural/computational, invertible)
	•	optional extra: termination order, completion hints, joiners

Output: a Presentation that Layer M can analyze/compile into a RewriteSystem.

Layer S (Surface syntaxes)

Surface ASTs, binding, contexts, elaboration:
	•	parameterized by a doctrine (Layer D) and a context kit (later)
	•	elaboration yields “core terms” (1-cells) in the doctrine’s generated language

For now: stub.

Layer B (Backends / models)

Interpretation of doctrine generators into a concrete target:
	•	interpreter or codegen to Haskell, circuits, IR, etc.
	•	must respect the doctrine’s equations (as proofs or validated tests)

For now: stub.

⸻

Haskell project scaffolding

Single Cabal package to start:

src/
  Strat/
    Meta/...
    Doctrine/Stub.hs
    Syntax/Stub.hs
    Model/Stub.hs
test/
  Strat/MetaSpec.hs

Suggested deps (keep minimal):
	•	base, containers, text
	•	optional: mtl (builder/state), prettyprinter (debug printing)
	•	tests: tasty, tasty-hunit (or hspec)

⸻

Layer M (Meta) — implement now

Design constraints (so you won’t rewrite this layer later)
	1.	Term representation must be abstract.
Rewriting/coherence algorithms must work over any term language that can supply:
	•	subterm positions
	•	substitution application
	•	matching (for rewriting)
	•	unification (for critical pairs), if available
When you later add binders / dependent structure, you implement a new TermLike instance (or new term type) rather than rewriting the meta engine.
	2.	Rules carry metadata.
This is where “relative coherence” and “structural vs computational” live. The meta engine uses metadata to decide which branchings produce which obligations.
	3.	Outcomes are graded, not binary.
	•	If a term language supplies unification, you can compute critical pairs automatically.
	•	If not, the engine still supports rewriting + manual joiners; critical pairs are “unknown/uncomputed”.

⸻

Module map (Layer M)

Strat.Meta.Types

Basic identifiers and shared types:

module Strat.Meta.Types where

import Data.Text (Text)

newtype RuleId = RuleId Int
  deriving (Eq, Ord, Show)

-- Tree positions: [] = root, [i,j] = child i then child j
type Pos = [Int]

data RuleClass = Structural | Computational
  deriving (Eq, Ord, Show)

data Orientation = LR | RL | Bidirectional | Unoriented
  deriving (Eq, Ord, Show)

Strat.Meta.Term.Class

Abstract interface for term languages.

Key idea: algorithms depend on these, not on a specific AST.

{-# LANGUAGE TypeFamilies #-}
module Strat.Meta.Term.Class where

import Strat.Meta.Types
import qualified Data.Map.Strict as M
import qualified Data.Set as S

-- Generic substitution mapping variables to terms
newtype Subst t = Subst { unSubst :: M.Map (Var t) t }
  deriving (Eq, Show)

class (Eq t, Ord (Var t)) => TermLike t where
  type Var t

  -- Observe term shape
  isVar   :: t -> Bool
  asVar   :: t -> Maybe (Var t)

  -- Enumerate positions (include [] by convention)
  positions :: t -> [Pos]

  subtermAt  :: t -> Pos -> Maybe t
  replaceAt  :: t -> Pos -> t -> Maybe t

  vars :: t -> S.Set (Var t)

  -- Apply a substitution to a term
  applySubst :: Subst t -> t -> t

  -- Rename variables (used to alpha-rename rules apart if needed)
  renameVars :: (Var t -> Var t) -> t -> t

-- For rewriting: match(pattern, target) instantiates vars in pattern
class TermLike t => Matchable t where
  match :: t -> t -> Maybe (Subst t)

-- For critical pairs: unify(t1, t2) instantiates vars in both terms
-- If a term language cannot support unification, you can omit this instance
class TermLike t => Unifiable t where
  unify :: t -> t -> Maybe (Subst t)

Notes:
	•	positions/subtermAt/replaceAt are required methods because later term representations (binders) won’t have “obvious” structural recursion.
	•	renameVars allows rule-variable scoping strategies (see below).

Strat.Meta.Term.FO

A concrete first-order term instance for early testing. Later, you add new instances (e.g., second-order/binding) without touching the meta engine.

module Strat.Meta.Term.FO where

import Strat.Meta.Term.Class
import Strat.Meta.Types
import qualified Data.Set as S
import qualified Data.Map.Strict as M
import Data.Text (Text)

newtype Sym = Sym Text
  deriving (Eq, Ord, Show)

data V = V Int
  deriving (Eq, Ord, Show)

data Term
  = TVar V
  | TApp Sym [Term]
  deriving (Eq, Ord, Show)

instance TermLike Term where
  type Var Term = V

  isVar (TVar _) = True
  isVar _        = False

  asVar (TVar v) = Just v
  asVar _        = Nothing

  positions t = go [] t
    where
      go p (TVar _)     = [p]
      go p (TApp _ as)  = p : concat [ go (p ++ [i]) a | (i,a) <- zip [0..] as ]

  subtermAt = ...        -- implement via recursion on Pos
  replaceAt = ...        -- implement via recursion on Pos

  vars (TVar v)    = S.singleton v
  vars (TApp _ as) = S.unions (map vars as)

  applySubst (Subst s) tm =
    case tm of
      TVar v -> M.findWithDefault tm v s
      TApp f as -> TApp f (map (applySubst (Subst s)) as)

  renameVars f tm =
    case tm of
      TVar v     -> TVar (f v)
      TApp h as  -> TApp h (map (renameVars f) as)

instance Matchable Term where
  match = ...   -- standard FO pattern matching

instance Unifiable Term where
  unify = ...   -- standard FO unification with occurs-check

Strat.Meta.Rule

Rules/equations plus metadata.

module Strat.Meta.Rule where

import Strat.Meta.Types
import Strat.Meta.Term.Class
import Data.Text (Text)

data Equation t = Equation
  { eqName   :: Text
  , eqClass  :: RuleClass
  , eqOrient :: Orientation
  , eqLHS    :: t
  , eqRHS    :: t
  } deriving (Eq, Show)

-- Oriented rule used by the rewrite engine
data Rule t = Rule
  { ruleId    :: RuleId
  , ruleName  :: Text
  , ruleClass :: RuleClass
  , lhs       :: t
  , rhs       :: t
  } deriving (Eq, Show)

Strat.Meta.Presentation

A doctrine/presentation is just a set of equations plus build helpers.

module Strat.Meta.Presentation where

import Strat.Meta.Rule
import Strat.Meta.Types
import Data.Text (Text)

data Presentation t = Presentation
  { presName     :: Text
  , presEqs      :: [Equation t]
  } deriving (Eq, Show)

-- Later: add optional fields like precedence/orderings, completion hints, etc.

Strat.Meta.RewriteSystem

Compile a Presentation into a set of oriented rewrite rules (possibly several “views” depending on policy).

module Strat.Meta.RewriteSystem where

import Strat.Meta.Rule
import Strat.Meta.Presentation
import Strat.Meta.Types

data RewriteSystem t = RewriteSystem
  { rsRules :: [Rule t]
  } deriving (Eq, Show)

-- A policy is needed because not all equations are oriented or safe for normalization
data RewritePolicy
  = UseOnlyComputationalLR
  | UseStructuralAsBidirectional
  | UseAllOriented
  deriving (Eq, Show)

compileRewriteSystem :: RewritePolicy -> Presentation t -> RewriteSystem t
compileRewriteSystem = ...

Keep RewritePolicy extensible: you will add “relative coherence modes” later.

Strat.Meta.Rewrite

Rewriting engine over Matchable terms.

module Strat.Meta.Rewrite where

import Strat.Meta.Types
import Strat.Meta.Rule
import Strat.Meta.RewriteSystem
import Strat.Meta.Term.Class

data Step t = Step
  { stepRule :: RuleId
  , stepPos  :: Pos
  , stepSubst :: Subst t
  } deriving (Eq, Show)

data Redex t = Redex
  { redexStep :: Step t
  , redexFrom :: t
  , redexTo   :: t
  } deriving (Eq, Show)

-- All one-step rewrites from a term
rewriteOnce :: Matchable t => RewriteSystem t -> t -> [Redex t]
rewriteOnce rs t = ...

applyStep :: TermLike t => (RuleId -> Rule t) -> Step t -> t -> Maybe t
applyStep = ...

-- Normalization with a step limit (since termination is not guaranteed)
normalize :: Matchable t => Int -> RewriteSystem t -> t -> t
normalize fuel rs t0 = ...

Notes:
	•	applyStep should be written in a way that can later validate proof objects (derivations/joiners).
	•	normalize is “best effort”; you will later plug in strategies.

Strat.Meta.CriticalPairs

Critical pair enumeration is where unification is required. If Unifiable isn’t available, you can return [] or Left NotSupported.

module Strat.Meta.CriticalPairs where

import Strat.Meta.Rule
import Strat.Meta.RewriteSystem
import Strat.Meta.Types
import Strat.Meta.Term.Class

data CriticalPair t = CriticalPair
  { cpRule1   :: RuleId
  , cpRule2   :: RuleId
  , cpPosIn2  :: Pos
  , cpPeak    :: t
  , cpLeft    :: t
  , cpRight   :: t
  , cpMgu     :: Subst t
  } deriving (Eq, Show)

-- Controls which overlaps matter (relative coherence)
data CPMode
  = CP_All
  | CP_OnlyStructural
  | CP_StructuralVsComputational
  deriving (Eq, Show)

criticalPairs
  :: (Unifiable t, TermLike t)
  => CPMode
  -> (RuleId -> Rule t)     -- lookup
  -> RewriteSystem t
  -> [CriticalPair t]
criticalPairs mode lookup rs = ...

Algorithm sketch (FO standard):
	•	For each ordered pair of rules (r1, r2)
	•	For each position p in lhs(r2) where the subterm is not a variable
	•	Compute mgu <- unify (lhs r1) (subtermAt (lhs r2) p)
	•	Let peak = applySubst mgu (lhs r2)
	•	Let left = applySubst mgu (replaceAt (lhs r2) p (rhs r1))
	•	Let right = applySubst mgu (rhs r2)
	•	Record (peak -> left, peak -> right) as a critical pair

Important future-proofing: variable capture is irrelevant in FO; later binder-aware terms will need binder-aware unification and positions semantics, but this module will not change—only the term instance does.

Strat.Meta.Coherence

This stores obligations and (optional) joiners.

module Strat.Meta.Coherence where

import Strat.Meta.CriticalPairs
import Strat.Meta.Rewrite
import Strat.Meta.RewriteSystem
import Strat.Meta.Rule
import Strat.Meta.Types
import Strat.Meta.Term.Class
import qualified Data.Map.Strict as M

data ObligationKind = NeedsJoin | NeedsCommute
  deriving (Eq, Show)

data Obligation t = Obligation
  { obKind  :: ObligationKind
  , obPair  :: CriticalPair t
  } deriving (Eq, Show)

-- A joiner is a “confluence diagram”: left ->* join <-* right
data Joiner t = Joiner
  { joinTerm :: t
  , leftDerivation  :: [Step t]
  , rightDerivation :: [Step t]
  } deriving (Eq, Show)

newtype JoinDB t = JoinDB (M.Map (RuleId, RuleId, Pos) (Joiner t))

obligationsFromCPs :: [CriticalPair t] -> [Obligation t]
obligationsFromCPs = ...

-- Validation: do the derivations actually rewrite to joinTerm?
-- (OK to stub initially; keep signature stable)
validateJoiner
  :: Matchable t
  => (RuleId -> Rule t)
  -> RewriteSystem t
  -> CriticalPair t
  -> Joiner t
  -> Bool
validateJoiner = ...

This is the scaffolding for “coherence assistant” features later:
	•	attempt automatic joining by bounded search
	•	completion procedures
	•	relative coherence checks (structural-only, commutation with computation, etc.)

⸻

Rule variable scoping (avoid freshening pain later)

Critical pair computation needs rules’ variables to be disjoint unless your unify handles variable namespaces robustly. Pick one of these now:

Option A (recommended): enforce “rule-local variables carry a scope”

In your concrete term types, define variables as (scope, localId) so different rules never collide.

Example for FO:

data V = V { vScope :: Int, vLocal :: Int }

Then the builder assigns vScope = ruleId (or a fresh scope) when constructing lhs/rhs.

This avoids having to implement freshenApart later, and works uniformly across term languages.

Option B: alpha-rename rules apart on demand

Keep renameVars in the interface and implement a freshenRule :: RuleId -> Rule t -> Rule t helper. This is more annoying when variables aren’t easily “freshenable”.

⸻

Minimal example (for testing the meta layer)

Start with a tiny FO rewrite system that has real overlaps.

Example: monoid right-association + unit elimination (terminating in practice on left-nesting)

Terms:
	•	e constant
	•	m(x,y) binary

Rules (Computational or Structural—your choice; this is just a test):
	•	m(e, x) -> x
	•	m(x, e) -> x
	•	m(m(x,y), z) -> m(x, m(y,z))  (right associate)

This creates critical pairs like m(m(e,x), y) etc.

In Strat.Meta.Examples.Monoid:
	•	build Presentation Term
	•	compile with RewritePolicy
	•	compute criticalPairs
	•	print obligations

Test file asserts:
	•	non-empty critical pairs
	•	normalize reduces some sample term

⸻

Stubs for lower layers (compile-time placeholders)

Strat.Doctrine.Stub

module Strat.Doctrine.Stub where

import Strat.Meta.Presentation

-- Eventually: richer doctrine API. For now: doctrine = presentation.
newtype Doctrine t = Doctrine { doctrinePres :: Presentation t }

Strat.Syntax.Stub

module Strat.Syntax.Stub where

-- Eventually: presheaf/second-order syntax + elaboration.
data SurfaceTerm = SurfaceStub

Strat.Model.Stub

module Strat.Model.Stub where

-- Eventually: interpretation of doctrine terms into a backend.
data Backend = BackendStub


⸻

Implementation order (Layer M)
	1.	Implement Types, Rule, Presentation.
	2.	Implement FO Term + Matchable + Unifiable.
	3.	Implement Rewrite (rewriteOnce, normalize with fuel).
	4.	Implement CriticalPairs using unify.
	5.	Implement Coherence obligation generation + joiner validation stub.
	6.	Add one example + a few tests.

⸻

What you will be able to verify after this scaffolding
	•	You can represent arbitrary doctrines as presentations (equations + metadata).
	•	You can orient equations into rewrite systems under a policy.
	•	You can compute critical pair “peaks” generically (for any Unifiable term language).
	•	You can generate a finite set of coherence obligations and store/validate joiners.

And crucially: when you later add binding / dependent syntax, you do it by adding new TermLike/Unifiable instances, not by rewriting any of the meta-layer algorithms.